%%% ====================================================================
%%%  BibTeX-file{
%%%     author          = "David Rhead",
%%%     version         = "1.00",
%%%     date            = "17 Feb 1990",
%%%     time            = "17:00 GMT",
%%%     filename        = "test.bib",
%%%     address         = "Cripps Computing Centre,
%%%                        University of Nottingham,
%%%                        University Park,
%%%                        Nottingham,
%%%                        NG7 2RD,
%%%                        United Kingdom",
%%%     telephone       = "+44 602 484848 Ext 2670",
%%%     FAX             = "+44 602 588138",
%%%     checksum        = "05151 839 2908 25082",
%%%     email           = "David_Rhead at uk.ac.nott.vme (JANET)",
%%%     codetable       = "ISO/ASCII",
%%%     keywords        = "bibliography, citation, references",
%%%     supported       = "no",
%%%     docstring       = "This BibTeX database file contains entries
%%%                        designed for testing whether a BibTeX style
%%%                        file lays references out as recommended by
%%%                        certain authorities.  (Note, however, that
%%%                        the BS 1629 examples are from the 1976
%%%                        edition.  The file needs updating to use
%%%                        examples from the 1989 edition instead.)
%%%
%%%                        The checksum field above contains a CRC-16
%%%                        checksum as the first value, followed by the
%%%                        equivalent of the standard UNIX wc (word
%%%                        count) utility output of lines, words, and
%%%                        characters.  This is produced by Robert
%%%                        Solovay's checksum utility.",
%%%  }
%%% ====================================================================


%% @COMMENT{Some standard works describing conventions for citations
%%      and bibliographies}


@ARTICLE{cambria_schuller, 
author={E. Cambria and B. Schuller and Y. Xia and C. Havasi}, 
journal={IEEE Intelligent Systems}, 
title={New Avenues in Opinion Mining and Sentiment Analysis}, 
year={2013}, 
volume={28}, 
number={2}, 
pages={15-21}, 
keywords={Internet;data mining;Web;opinion mining;public opinion;sentiment analysis;Context awareness;Data mining;Information analysis;Intelligent systems;Knowledge discovery;Market research;Natural language processing;Pragmatics;Semantics;AI;Context awareness;Data mining;Information analysis;Intelligent systems;Knowledge discovery;Market research;NLP;Natural language processing;Pragmatics;Semantics;intelligent systems;opinion mining;sentiment analysis}, 
doi={10.1109/MIS.2013.30}, 
ISSN={1541-1672}, 
month={March},}




@article{wilson_wiebe,
author = { Theresa  Wilson and  Janyce  Wiebe and  Paul  Hoffmann},
title = {Recognizing Contextual Polarity: An Exploration of Features for Phrase-Level Sentiment Analysis},
journal = {Computational Linguistics},
volume = {35},
number = {3},
pages = {399-433},
year = {2009},
doi = {10.1162/coli.08-012-R1-06-90},

URL = { 
        https://doi.org/10.1162/coli.08-012-R1-06-90
    
},
eprint = { 
        https://doi.org/10.1162/coli.08-012-R1-06-90
    
}
,
    abstract = { Many approaches to automatic sentiment analysis begin with a large lexicon of words marked with their prior polarity (also called semantic orientation). However, the contextual polarity of the phrase in which a particular instance of a word appears may be quite different from the word's prior polarity. Positive words are used in phrases expressing negative sentiments, or vice versa. Also, quite often words that are positive or negative out of context are neutral in context, meaning they are not even being used to express a sentiment. The goal of this work is to automatically distinguish between prior and contextual polarity, with a focus on understanding which features are important for this task. Because an important aspect of the problem is identifying when polar terms are being used in neutral contexts, features for distinguishing between neutral and polar instances are evaluated, as well as features for distinguishing between positive and negative contextual polarity. The evaluation includes assessing the performance of features across multiple machine learning algorithms. For all learning algorithms except one, the combination of all features together gives the best performance. Another facet of the evaluation considers how the presence of neutral instances affects the performance of features for distinguishing between positive and negative polarity. These experiments show that the presence of neutral instances greatly degrades the performance of these features, and that perhaps the best way to improve performance across all polarity classes is to improve the system's ability to identify when an instance is neutral. }
}




